---
title: "Human Activity Recognition"
author: "Andrew William Judd"
date: "May 16, 2016"
output: html_document
---

# Executive Summary

In this study, we analyzed the personal activity data which is provided through devices such as _Jawbone Up_, _Nike FuelBand_ and _Fitbit_.  Using all of the information, we are able to analyze various factors which directly affect how well the person is completing the exercise.  The data was made available through their [website](http://groupware.les.inf.puc-rio.br/har).

Numerous machine learning models were applied to this data set in order to determine which one would best predict the type of activity that the person was performing.  We have determined that the **random forest** machine learning model provided the most accurate results and have applied that to our test data set in order to complete the study.

# Exploratory Analysis

## Setup Environment

Start by setting up the environment.  In order to do this we do the following:

 * Load all of the necessary libraries
 * Have a consistent seed value - that way our results are reproducible
 * Retrieve the data from the source:
    * [Training Set](http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)
    * [Testing Set](http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)
 * Cleanse the data

```{r}
library(caret)
library(rpart)
library(rpart.plot)

seed <- 19
train.url <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
test.url <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
```

```{r eval=FALSE}
train.data <- read.csv(url(train.url), na.strings = c('NA', '#DIV/0!', ''))
test.data <- read.csv(url(test.url), na.strings = c('NA', '#DIV/0!', ''))
```

```{r echo=FALSE}
# Do we already have the data loaded?
if(!exists('train.data')) {
    # We don't, so check if we have the training set
    if(!file.exists('training.csv')) {
        # We don't, so download it
        download.file(train.url, 'training.csv')
    }
    
    # Load the data into memory
    train.data <- read.csv('training.csv', na.strings = c('NA', '#DIV/0!', ''))
}

# Do we already have the data loaded?
if(!exists('test.data')) {
    # We don't, so check if we have the testing set
    if(!file.exists('test.csv')) {
        # We don't, so download it
        download.file(test.url, 'test.csv')
    }
    
    # Load the data into memory
    test.data <- read.csv('test.csv', na.strings = c('NA', '#DIV/0!', ''))
}
```

Now that the data has been loaded into memory, it is time to prepare it.

## Prepare the Data

In order to get a good sense of how our models are able to predict the results, we need to start by splitting our training data into two sets.  To do this, we split the **training** set into two sections, one that is *70%* of the data, and the other which is *30%*.

After splitting the data, we will remove the first 5 columns as they do not have anything to do with the predictions.  This is because they are the following:

 * `X`
 * `user_name`
 * `raw_timestamp_part_1`
 * `raw_timestamp_part_2`
 * `cvtd_timestamp`

```{r, eval = FALSE}
set.seed(seed)

# Partition the data for further analysis
data.toTrain <- createDataPartition(train.data$classe, p = 0.7, list = FALSE)

# Split the data set into the two portions
data.train <- train.data[data.toTrain, ]
dim(data.train)
data.test <- train.data[-data.toTrain, ]
dim(data.test)

# Remove columns that we know will provide no value (names and timestamps)
data.train <- data.train[, -(1:5)]
data.test <- data.test[, -(1:5)]
```

Now that the data has been loaded, we need to first get rid of any data that only have one unique value or have both of the following characteristics (based on the near zero variance):

 * very few unique values relative to the number of samples
 * ratio of the frequency of the most common value to the frequency of the second most common value is large

```{r, eval = FALSE}
data.nearZero <- nearZeroVar(data.train)
data.train.cleaned <- data.train[,-data.nearZero]
dim(data.train.cleaned)
data.test.cleaned <- data.test[,-data.nearZero]
dim(data.test.cleaned)
```

After looking at the data, we noticed that there were multiple `NA` values which could affect the overall accuracy of the data.  Because of that, we will further reduce the columns based on whether or not the data is mostly `NA`.

```{r, eval = FALSE}
# Grab a list where they are mostly "NA" values
data.na <- sapply(
    data.train.cleaned,
    function(x) 
        mean(is.na(x))
) > 0.95

# Filter out the data from both the training, and the test data sets
data.train.cleaned <- data.train.cleaned[, data.na == FALSE]
dim(data.train.cleaned)

data.test.cleaned <- data.test.cleaned[, data.na == FALSE]
dim(data.test.cleaned)
```

Now that the data is all tidied up, it is time to apply the various models to it.  This clean up left us with only **54** potential factors.

# Train the Different Prediction Models

In order to ensure we would have the most accurate predictions possible, we will evaluate the following three machine learning techniques:

 * Decision Trees
 * Generalized Boosted
 * Random Forest

## Decision Trees

Let's start by training the decision tree with the training data set.

```{r cache = TRUE, warning = FALSE, eval = FALSE}
set.seed(seed)
result.decision_tree.model <- rpart(
    classe ~ ., data = data.train
)
```

Now that the model has been created, let's evaluate our results.

```{r cache = TRUE, warning = FALSE, eval = FALSE}
result.decision_tree.predict <- predict(
    result.decision_tree.model,
    newdata = data.test,
    type='class'
)

result.decision_tree.confusion <- confusionMatrix(
    result.decision_tree.predict,
    data.test$classe
)

result.decision_tree.confusion
```

The overall accuracy of this model was: **81.05%**

For a breakdown of this approach, please refer to Appendix **Figure 1** for a detailed breakdown of this plot.

## Generalized Boosted

Let's start by training the generalized boost with the training data set.

```{r cache = TRUE, warning = FALSE, eval = FALSE}
set.seed(seed)

result.gbm.control <- trainControl(
    method = 'repeatedcv',
    number = 5,
    repeats = 1
)

if(!exists('result.gbm.model')) {
    result.gbm.model <- train(
        classe ~ .,
        data = data.train.cleaned,
        method = 'gbm',
        trControl = result.gbm.control,
        verbose = FALSE
    )   
}
```

Now that the model has been created, let's evaluate our results.

```{r cache = TRUE, warning = FALSE, eval = FALSE}
result.gbm.predict <- predict(
    result.gbm.model,
    newdata = data.test
)

result.gbm.confusion <- confusionMatrix(
    result.gbm.predict,
    data.test$classe
)

result.gbm.confusion
```

The overall accuracy of this model was: **98.76%**

For a breakdown of this approach, please refer to Appendix **Figure 2** for a detailed breakdown of this plot.

## Random Forest

### Train It

```{r cache = TRUE, warning = FALSE, eval = FALSE}
set.seed(seed)

result.random_forest.control <- trainControl(
    method='cv',
    number = 3,
    verboseIter = FALSE
)

# Did we already create the model?
if(!exists('result.random_forest.model')) {
    # We didn't, so make it
    result.random_forest.model <- train(
        classe ~ .,
        data = data.train.cleaned,
        method = 'rf',
        trControl = result.random_forest.control
    )
}

result.random_forest.model$finalModel
```

Now that the model has been created, let's evaluate our results.

```{r cache = TRUE, warning = FALSE, eval = FALSE}
result.random_forest.predict <- predict(
    result.random_forest.model,
    newdata = data.test.cleaned
)

result.random_forest.confusion <- confusionMatrix(
    result.random_forest.predict,
    data.test.cleaned$classe
)
```

The overall accuracy of this model was: **99.80%**

For a breakdown of this approach, please refer to Appendix **Figure 3** for a detailed breakdown of this plot.

# Prediction

Based on the various accuracies listed above, we have decided to use the **random forest** model to predict the data that we expect to come out of the testing data set.

```{r, eval = FALSE}
output <- predict(
    result.random_forest.model,
    newdata = test.data
)

output
```


# Appendix

```{r, eval = FALSE, echo = FALSE}
plot(
    result.decision_tree.confusion$table,
    col = result.decision_tree.confusion$byClass, 
    main = paste(
        'Decision Tree - Accuracy =',
        round(result.decision_tree.confusion$overall['Accuracy'], 4)
    )
)
```

**Figure 1** - Decision Tree Results

```{r, eval = FALSE, echo = FALSE}
plot(
    result.gbm.confusion$table,
    col = result.gbm.confusion$byClass, 
    main = paste(
        'GBM - Accuracy =',
        round(result.gbm.confusion$overall['Accuracy'], 4)
    )
)
```

**Figure 2** - Generalized Boosted Results

```{r, eval = FALSE, echo = FALSE}
plot(
    result.random_forest.confusion$table,
    col = result.random_forest.confusion$byClass,
    main = paste(
        'Random Forest - Accuracy =',
        round(result.random_forest.confusion$overall['Accuracy'], 4)
    )
)
```

**Figure 3** - Random Forest Results